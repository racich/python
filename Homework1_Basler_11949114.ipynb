{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework exercise 1\n",
    "## Deadline: upload to Moodle by 17 May 18:00 h\n",
    "\n",
    "__Please submit your homework either as a Jupyter Notebook or using .py files.__\n",
    "\n",
    "If you use .py files, please also include a PDF containing the output of your code and your explanations. Either way, the code needs to be in a form that can be easily run on another computer.\n",
    "\n",
    "__Name:__Fabian Basler\n",
    "\n",
    "\n",
    "The name of the file that you upload should be named *Homework1_YourLastName_YourStudentID*.\n",
    "\n",
    "Reminder: you are required to attend class on 18 May to earn points for this homework exercise unless you have a valid reason for your absence.\n",
    "\n",
    "You are expected to work on this exercise individually. If any part of the questions is unclear, please ask on the Moodle forum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SEC EDGAR__\n",
    "\n",
    "Filings made by companies to the regulator are another very useful source of text data. The most important source in this regard is the US Securities and Exchange Commission (SEC).\n",
    "\n",
    "The SEC provides information on how to access their filings here: https://www.sec.gov/edgar/searchedgar/accessing-edgar-data.htm\n",
    "\n",
    "Please write a function that\n",
    "\n",
    "* downloads index files sorted by form type for a particular day or a list of days\n",
    "* then downloads the _HTML versions_ of the filings made on that day (or each day in the list), with an optional argument that can specify the form type if you want to access only files of one such form type. Note that you can identify the file containing the main filing, which is the file to be downloaded, by considering the column 'Type' in the table, e.g., here: https://www.sec.gov/Archives/edgar/data/946644/0001493152-21-005524-index.htm\n",
    "\n",
    "Please write another function that \n",
    "* downloads the HTML versions of the files of form type 10-Q file on a given day\n",
    "* removes all tables and images from the files if there are any\n",
    "* returns a DataFrame in which the columns correspond to the different parts/items of the form and the content of each filing is written to one row of the DataFrame. Item here is a technical term here as you will see when looking at such filings, e.g., here: https://www.sec.gov/Archives/edgar/data/1530425/000147793221001290/arrt_10q.htm ;  the items are numbered and items with the same number that are contained in the same part of the filing always have the same name.\n",
    "\n",
    "Please test your code for days comprising a total of at least 10 filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import requests\n",
    "import datetime as dt\n",
    "from math import ceil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_htm(url, dire , name, form):\n",
    "    # request the url and put it in bs\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "    #select all .htm documents if form is None\n",
    "    if form==None:\n",
    "        doc_links= [a.get(\"href\") for a in soup.find_all(\"a\",href= re.compile(r\".htm$\"))]\n",
    "    # select only links with a text similar than the form\n",
    "    else:\n",
    "        form_re= re.compile(re.escape(form), re.I)\n",
    "        doc_links= [a.get(\"href\") for a in soup.find_all(\"a\", text = form_re)]\n",
    "    # downloads the document to the directory\n",
    "    for link in doc_links:\n",
    "        time.sleep(0.3)\n",
    "        r= requests.get(\"https://www.sec.gov/\"+link)\n",
    "        open(f'{dire}/{name}.htm', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_1(dates,form=None):\n",
    "    \"\"\"\n",
    "    This function downloads the SEC files for given dates.\n",
    "    Dates must be a list of strings.\n",
    "    The format of the date has to be yyyy-mm-dd.\n",
    "    \"\"\"\n",
    "    # makes the input to lists datetimes\n",
    "    if type(dates) == str:\n",
    "        dates = [dates]\n",
    "    dates_dt = [dt.datetime.strptime(date, '%Y-%m-%d').date() for date in dates]\n",
    "    dates_dt.sort()\n",
    "\n",
    "    for date in dates_dt:\n",
    "        print(\"new date started\")\n",
    "        # extracting items of the date\n",
    "        year = str(date.year)\n",
    "        qrt = str(ceil(date.month/3))\n",
    "        month = date.strftime('%m')\n",
    "        day = date.strftime('%d')\n",
    "        dire = f\"C:/Users/Fabian/Desktop/Python/projects/PY for Finance II/bs_scrap/SEC{year}{month}{day}\"\n",
    "        # creates a new directory for the date if doesn´t exists\n",
    "        if not os.path.exists(dire):\n",
    "            os.makedirs(dire)\n",
    "        # download of the .idx file\n",
    "        url= f\"https://www.sec.gov/Archives/edgar/daily-index/{year}/QTR{qrt}/master.{year}{month}{day}.idx\"\n",
    "        r = requests.get(url)\n",
    "        open(f'{dire}/master.{year}{month}{day}.idx', 'wb').write(r.content)\n",
    "\n",
    "        # opens the idx file and stores it in a dataframe. cleans the data\n",
    "        with open(f\"{dire}/master.{year}{month}{day}.idx\",\"r\", encoding=\"utf-8\") as fp:\n",
    "            df = pd.read_csv(fp,sep=\"|\",header=4, skip_blank_lines=True)\n",
    "        df = df[1:]\n",
    "        df[\"Date Filed\"] = pd.to_datetime(df[\"Date Filed\"],format='%Y%m%d')\n",
    "        df[\"File Name\"] = \"https://www.sec.gov/Archives/\" + df[\"File Name\"].str.replace(\".txt\", \"-index.htm\")\n",
    "        # selects only the searched form in the df\n",
    "        if form != None:\n",
    "            df = df[df['Form Type'] == form]\n",
    "        df.sort_values(by=['Form Type'], inplace=True)\n",
    "        # downloads the htm files\n",
    "        for url, CIK in zip(df['File Name'],df[\"CIK\"]):\n",
    "            time.sleep(1)\n",
    "            save_htm(url, dire, CIK, form)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "new date started\n",
      "ipykernel_launcher:34: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "new date started\n"
     ]
    }
   ],
   "source": [
    " download_1([\"2020-03-23\",\"2012-12-17\"],\"8-K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_split(text, regex, company_CIK):\n",
    "    \"\"\"\n",
    "    returns a dictionairy with the items as keys and the merged text as value\n",
    "    \"\"\"\n",
    "    keys = [x.upper() for x in regex.findall(text)]\n",
    "    text_split = regex.split(text)\n",
    "    # drops first string because it occures before the first item\n",
    "    text_split.pop(0)\n",
    "    dummy_dict = {}\n",
    "    # adds the string if the key already exists, sets to the string otherwise\n",
    "    for key, split in zip(keys,text_split):\n",
    "        if key in dummy_dict.keys():\n",
    "            dummy_dict[key] = dummy_dict[key] + split\n",
    "        else:\n",
    "            dummy_dict[key]= split\n",
    "    df = pd.DataFrame(data=dummy_dict, index=[str(company_CIK)])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_10Q(url, dire , name):\n",
    "    # request the url and put it in bs\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "    # gets link of 10-Q htm\n",
    "    doc_links= [a.get(\"href\") for a in soup.find_all(\"a\", text = re.compile(r\"10.?q.htm\"))]\n",
    "    time.sleep(1)\n",
    "    # downloads the document to the directory\n",
    "    Dummy_Frame = pd.DataFrame()\n",
    "    for link in doc_links:\n",
    "        r= requests.get(\"https://www.sec.gov/\"+link)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        # delets tables and pictures\n",
    "        for item in soup.find_all([\"table\", \"picture\"]):\n",
    "            item.decompose()\n",
    "\n",
    "        with open(f'{dire}/{name}.html', \"w\", encoding = 'utf-8') as file:\n",
    "            file.write(str(soup))\n",
    "        \n",
    "        text = soup.get_text()\n",
    "        re_item = re.compile(r\"ITEM [0-9]\",re.I)\n",
    "        df = dict_split(text, re_item, name)\n",
    "        Dummy_Frame = Dummy_Frame.append(df, sort=False)\n",
    "    return Dummy_Frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_2(dates):\n",
    "    \"\"\"\n",
    "    This function downloads the SEC files for given dates.\n",
    "    Dates must be a list of strings.\n",
    "    The format of the date has to be yyyy-mm-dd.\n",
    "    \"\"\"\n",
    "    # makes the input to lists datetimes\n",
    "    if type(dates) == str:\n",
    "        dates = [dates]\n",
    "    dates_dt = [dt.datetime.strptime(date, '%Y-%m-%d').date() for date in dates]\n",
    "    dates_dt.sort()\n",
    "\n",
    "    \n",
    "    DummyFrame = pd.DataFrame()\n",
    "    for date in dates_dt:\n",
    "        print(\"new date started\")\n",
    "        # extracting items of the date        \n",
    "        year = str(date.year)\n",
    "        qrt = str(ceil(date.month/3))\n",
    "        month = date.strftime('%m')\n",
    "        day = date.strftime('%d')\n",
    "        dire = f\"C:/Users/Fabian/Desktop/Python/projects/PY for Finance II/bs_scrap2/SEC{year}{month}{day}\"\n",
    "        # creates a new directory for the date if doesn´t exists\n",
    "        if not os.path.exists(dire):\n",
    "            os.makedirs(dire)\n",
    "        # download of the .idx file\n",
    "        url= f\"https://www.sec.gov/Archives/edgar/daily-index/{year}/QTR{qrt}/master.{year}{month}{day}.idx\"\n",
    "        r = requests.get(url)\n",
    "        time.sleep(1)\n",
    "        open(f'{dire}/master.{year}{month}{day}.idx', 'wb').write(r.content)\n",
    "\n",
    "        # opens the idx file and stores it in a dataframe. cleans the data\n",
    "        with open(f\"{dire}/master.{year}{month}{day}.idx\",\"r\", encoding=\"utf-8\") as fp:\n",
    "            df = pd.read_csv(fp,sep=\"|\",header=4, skip_blank_lines=True)\n",
    "        df = df[1:]\n",
    "        df[\"Date Filed\"] = pd.to_datetime(df[\"Date Filed\"],format='%Y%m%d')\n",
    "        df[\"File Name\"] = \"https://www.sec.gov/Archives/\" + df[\"File Name\"].str.replace(\".txt\", \"-index.htm\")\n",
    "        df = df[df['Form Type'] == \"10-Q\"]\n",
    "        # downloads the htm files and appends the DataFrame\n",
    "        for url, CIK in zip(df['File Name'],df[\"CIK\"]):\n",
    "            time.sleep(5)\n",
    "            DummyFrame = DummyFrame.append(save_10Q(url, dire, CIK))\n",
    "    return DummyFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "new date started\n",
      "ipykernel_launcher:37: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "scrap2 = download_2(\"2020-03-23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                    ITEM 1  \\\n1129096                                                NaN   \n1375618                                                NaN   \n1404935                                                NaN   \n1546853  : FINANCIAL STATEMENTS   SKKYNET CLOUD SYSTEMS...   \n1715611  . CONDENSED CONSOLIDATED INTERIM FINANCIAL STA...   \n\n                                                    ITEM 2  \\\n1129096                                                NaN   \n1375618                                                NaN   \n1404935                                                NaN   \n1546853  : MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINA...   \n1715611   – MANAGEMENT’S DISCUSSION AND ANALYSIS OF FIN...   \n\n                                                    ITEM 3  \\\n1129096                                                NaN   \n1375618                                                NaN   \n1404935                                                NaN   \n1546853  : QUANTITATIVE AND QUALITATIVE DISCLOSURES ABO...   \n1715611   - QUANTITATIVE AND QUALITATIVE DISCLOSURES AB...   \n\n                                                    ITEM 4  \\\n1129096                                                NaN   \n1375618                                                NaN   \n1404935                                                NaN   \n1546853  : CONTROLS AND PROCEDURES   This report includ...   \n1715611   – CONTROLS AND PROCEDURES   Evaluation of Dis...   \n\n                                     ITEM 5  \\\n1129096                                 NaN   \n1375618                                 NaN   \n1404935                                 NaN   \n1546853  : OTHER INFORMATION   None.          \n1715611   – OTHER INFORMATION   None          \n\n                                                    ITEM 6  \\\n1129096                                                NaN   \n1375618                                                NaN   \n1404935                                                NaN   \n1546853  : EXHIBITS         SIGNATURES   In accordance ...   \n1715611   – EXHIBITS    The following exhibits are incl...   \n\n                                                    ITEM 7  \n1129096                                                NaN  \n1375618                                                NaN  \n1404935                                                NaN  \n1546853                                                NaN  \n1715611  , Management’s Discussion and Analysis of Fina...  \n"
     ]
    }
   ],
   "source": [
    "print(scrap2.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pythonjvsc74a57bd0d3adbaf49ae7f507e83f0ccfbb2546a5cc19668fb515a7486c42bc7952ccb80e",
   "display_name": "Python 3.7.4 64-bit ('Finance': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "metadata": {
   "interpreter": {
    "hash": "d3adbaf49ae7f507e83f0ccfbb2546a5cc19668fb515a7486c42bc7952ccb80e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}